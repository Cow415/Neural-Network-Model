{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e16dba",
   "metadata": {},
   "source": [
    "# Final Project-Building NN From Scratch\n",
    "Work from this script, pull basic function and classes from other built script. \n",
    "\\\n",
    "First: Let's import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d92b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append('os.getcwd()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05e46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in built modules\n",
    "from layers.conv import Conv2D\n",
    "from layers.relu import ReLU\n",
    "from layers.pool import MaxPool2D\n",
    "from layers.flatten import Flatten\n",
    "from layers.dense import Dense\n",
    "\n",
    "from model.sequential import SequentialModel\n",
    "from loss.softmax_ce import SoftmaxCrossEntropyLoss\n",
    "from optim.adam import Adam\n",
    "\n",
    "from data.dataset import MNISTDataset\n",
    "from data.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f3fef",
   "metadata": {},
   "source": [
    "Assume the the file is unloaded as npz. \n",
    "\n",
    "Load in the MNIST Data; then pull in the Dataset and DataLoader functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d9d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 1, 28, 28) (60000,)\n",
      "Testing data shape: (10000, 1, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "data = np.load(\"/Users/caozehuang/Documents/GitHub/Neural-Network-Model/data/mnist.npz\")\n",
    "X_train = data['x_train']  # Note: lowercase keys from unpacker\n",
    "y_train = data['y_train']\n",
    "\n",
    "X_test = data['x_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "# Check Shapes\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e821dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crease Dataset and DataLoader\n",
    "train_dataset = MNISTDataset(X_train, y_train)\n",
    "test_dataset = MNISTDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02de19",
   "metadata": {},
   "source": [
    "Construct the CNN class and propagations using the sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc72c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequentialModel([\n",
    "    Conv2D(1, 8, 3, padding=1),\n",
    "    ReLU(),\n",
    "    MaxPool2D(2, 2),\n",
    "\n",
    "    Conv2D(8, 16, 3, padding=1),\n",
    "    ReLU(),\n",
    "    MaxPool2D(2, 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(16 * 7 * 7, 128),\n",
    "    ReLU(),\n",
    "    Dense(128, 10)           \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33ce9f",
   "metadata": {},
   "source": [
    "Loss and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39dafaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SoftmaxCrossEntropyLoss()\n",
    "optimizer = Adam(model.params(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f208d",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0366e7c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3,3) (8,3,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m----> 6\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mforward(logits, y)\n\u001b[1;32m      8\u001b[0m     grad \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/GitHub/Neural-Network-Model/cnn_comp/model/sequential.py:16\u001b[0m, in \u001b[0;36mSequentialModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mDefine the forward pass through all layers\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/GitHub/Neural-Network-Model/cnn_comp/layers/conv.py:48\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 h \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[1;32m     46\u001b[0m                 w \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[1;32m     47\u001b[0m                 out[n,f,i,j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m---> 48\u001b[0m                     x_pad[n,:,h:h\u001b[38;5;241m+\u001b[39mKH,w:w\u001b[38;5;241m+\u001b[39mKW] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[f]\n\u001b[1;32m     49\u001b[0m                 ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb[f]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3,3) (8,3,3) "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    correct = total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        logits = model.forward(X)\n",
    "        loss = criterion.forward(logits, y)\n",
    "        grad = criterion.backward()\n",
    "\n",
    "        model.backward(grad)\n",
    "        optimizer.step(model.gradients())\n",
    "\n",
    "        running_loss += loss * len(y)\n",
    "        correct += (logits.argmax(axis=1) == y).sum()\n",
    "        total += len(y)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}: \"\n",
    "        f\"loss={running_loss/total:.4f}, \"\n",
    "        f\"acc={correct/total:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30597e62",
   "metadata": {},
   "source": [
    "Evaluation and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374963fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Check\n",
    "correct = total = 0\n",
    "\n",
    "for X, y in test_loader:\n",
    "    logits = model.forward(X)\n",
    "    preds = logits.argmax(axis=1)\n",
    "    correct += (preds == y).sum()\n",
    "    total += len(y)\n",
    "\n",
    "print(f\"Test accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit Debug\n",
    "tiny_ds = MNISTDataset(X_train[:10], y_train[:10])\n",
    "tiny_loader = DataLoader(tiny_ds, batch_size=5, shuffle=True)\n",
    "# If 100% accuracy not reached, backward bug exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b6f20",
   "metadata": {},
   "source": [
    "Shape Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logits.shape == (X.shape[0], 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
